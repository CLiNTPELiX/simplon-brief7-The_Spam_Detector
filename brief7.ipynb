{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keywords: NLP (TALN), classification.\n",
    "\n",
    "# The Spam Detector\n",
    "\n",
    "## Description\n",
    "\n",
    "Madame Esposito développe pour son entreprise un chatbot dans le but de répondre automatiquement à ses nombreux clients. Cependant son programme recoit un grand nombre de message malveillant ou à caractere publicitaire ce qui degrade les performance de son bot en plus d'occasionner des traitements informatiques se répercutant sur sa facture d'electricité.\n",
    "\n",
    "Madame Esposito vous a contacté afin de créer un programme capable de detecter automatiquement les SPAM. Pour cela, elle a construit un jeux de donnée comportant un ensemble de SMS de type SPAM et NON SPAM (HAM), disponible à l'addresse suivante : http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/\n",
    "\n",
    "Par ailleurs, afin d'intégrer les résultats dans son équipe, elle nous demande les choses suivantes:\n",
    "\n",
    "Afin d'estimer le cout du devellopement et suivre le projet, une checklist des taches à réaliser doit être rédigé.\n",
    "https://trello.com/b/JNiVTMvb/spam-detector\n",
    "\n",
    "Vous devez créer des fonctions pour les diférentes partie de votre code afin de pouvoir les réutiliser facilement\n",
    "Vous devez effectuer une validation croisé (cross-validation) sur 10 jeux de'apprentissage et de test différent. Le seed doit être fixé à 42 et le jeux de test doit représenter 20% des données.\n",
    "Comparer au moins trois algorithme de classification en terme de f1 score. Lequel est le plus puissant ?\n",
    "\n",
    "## Bonus¶\n",
    "\n",
    "Pouvez améliorer les résultats ?\n",
    "\n",
    "* est-ce que la lemmatisation améliore les résultats ?\n",
    "* est-ce que la racinisation (stemming) améliore les résultats ?\n",
    "Une fois ces étapesréalisées, reproduire la même expérience avec le jeux suivant, représant cette fois des commentaires Youtube : https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection\n",
    "\n",
    "Les performances sont-elles similaire à ceux obtenus avec le jeux de données précedent ?\n",
    "\n",
    "Madame esposito souhaite controler si les modéles appris avec le premier jeux de données sont capable de prédire les données de test du deuxième jeu et vice-versa. Réaliser un tableau comparant\n",
    "\n",
    "* les résultats de prédiction du modeles appris sur les SPAN SMS pour prédire les SPAM commentaire youtube et\n",
    "* les résultats de prédiction du modeles appris surles SPAM commentaire youtube pour prédire les SPAM SMS youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "# import plotly.express as px # on est pas dans le bon environnement\n",
    "\n",
    "## nltk\n",
    "import nltk\n",
    "# nltk.download() ## à executer qu'une fois\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "## sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "### models ML\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression\n",
    "from sklearn import svm      # Support Vector Machine\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "### evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# *************************************************************************\n",
    "#### Import librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "### Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import recall_score , precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "#vis\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "#os\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Randomization of Workgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Myriam', 'Sacia', 'Fatima', 'Pierre-Etienne']\n",
      "['Olivier', 'Jean-Pierre', 'Ludo', 'Julien']\n",
      "['Joshua', 'Caroline', 'Dan', 'Constant']\n",
      "['Hachem', 'Anthony', 'Cecilia', 'Wiem', 'Bassem']\n"
     ]
    }
   ],
   "source": [
    "app = 'Anthony Constant Joshua Fatima Julien Bassem Caroline Dan Ines Nidhal Sacia Xavier Roger Hachem Jean-Pierre Myriam Ludo Olivier Pierre-Etienne Wiem Cecilia'.split()\n",
    "s = app\n",
    " \n",
    "np.random.seed(1)\n",
    "rapp = [s[i] for i in np.random.choice(21, 21, replace=False)]\n",
    "for i in range(4):\n",
    "    e = rapp\n",
    "    print(e[4*i:4*i+4] + ([e[-1]] if i == 3 else []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Proposed Plan\n",
    "\n",
    "1) *Veille en Traitement du langage + checklist + 45min*\n",
    "\n",
    "https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32\n",
    "\n",
    "https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1\n",
    "\n",
    "https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63\n",
    "\n",
    "* Parsing and tokenization ?\n",
    "PARSING involves undertaking grammatical analysis for the provided sentence.\n",
    "\n",
    "STEMMING refers to the process of slicing the end or the beginning of words with the intention of removing affixes & suffixes.\n",
    "\n",
    "LEMMATIZATION has the objective of reducing a word to its base form and grouping together different forms of the same word.\n",
    "\n",
    "TOKENIZATION is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called tokens, and at the same time throwing away certain characters, such as punctuation.\n",
    "\n",
    "* Advantage of TFIDF ?\n",
    "One approach in NLP is to rescale the frequency of words by how often they appear in all texts (not just the one we are analyzing) so that the scores for frequent words like “the”, that are also frequent across other texts, get penalized. This approach to scoring is called “Term Frequency — Inverse Document Frequency” (TFIDF), and improves the bag of words by weights. Through TFIDF frequent terms in the text are “rewarded” (like the word “they” in our example), but they also get “punished” if those terms are frequent in other texts we include in the algorithm too. On the contrary, this method highlights and “rewards” unique or rare terms considering all texts. Nevertheless, this approach still has no context nor semantics.\n",
    "\n",
    "* Stops words ?\n",
    "STOP WORDS removal includes getting rid of common language articles, pronouns and prepositions such as “and”, “the” or “to” in english.\n",
    "\n",
    "* Vectorization ? Bag of words ?\n",
    "The BAG OF WORDS is a commonly used model in NLP that allows you to count all words in a piece of text.\n",
    "\n",
    "In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:\n",
    "\n",
    "* tokenizing strings and giving an integer id for each possible token (for instance by using white-spaces and punctuation as token separators)\n",
    "* counting the occurrences of tokens in each document\n",
    "* normalizing and weighting with diminishing importance tokens that occur in the majority of samples / documents\n",
    "\n",
    "Each individual token occurrence frequency (normalized or not) is treated as a feature. The vector of all the token frequencies for a given document is considered as a multivariate sample. A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to punkt...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk # installation of NLTK\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', 'punkt') #comment this line after kernel restart\n",
    "print(stopwords.words('french')) # French for testing my below quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Et', 'si', 'quelquefois', ',', 'sur', 'les', 'marches', \"d'un\", 'palais', ',', 'sur', \"l'herbe\", 'verte', \"d'un\", 'fossé', ',', 'vous', 'vous', 'réveillez', ',', \"l'ivresse\", 'déjà', 'diminuée', 'ou', 'disparue', ',', 'demandez', 'au', 'vent', ',', 'à', 'la', 'vague', ',', 'à', \"l'étoile\", ',', 'à', \"l'oiseau\", ',', 'à', \"l'horloge\", ';', 'à', 'tout', 'ce', 'qui', 'fuit', ',', 'à', 'tout', 'ce', 'qui', 'gémit', ',', 'à', 'tout', 'ce', 'qui', 'roule', ',', 'à', 'tout', 'ce', 'qui', 'chante', ',', 'à', 'tout', 'ce', 'qui', 'parle', ',', 'demandez', 'quelle', 'heure', 'il', 'est', '.', 'Et', 'le', 'vent', ',', 'la', 'vague', ',', \"l'étoile\", ',', \"l'oiseau\", ',', \"l'horloge\", ',', 'vous', 'répondront', ',', 'il', 'est', \"l'heure\", 'de', \"s'enivrer\", ';', 'pour', 'ne', 'pas', 'être', 'les', 'esclaves', 'martyrisés', 'du', 'temps', ',', 'enivrez-vous', ',', 'enivrez-vous', 'sans', 'cesse', 'de', 'vin', ',', 'de', 'poésie', ',', 'de', 'vertu', ',', 'à', 'votre', 'guise', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"\"\"Et si quelquefois, sur les marches d'un palais, sur l'herbe verte d'un fossé, vous vous réveillez, l'ivresse déjà diminuée ou disparue, demandez au vent, à la vague, à l'étoile, à l'oiseau, à l'horloge; à tout ce qui fuit, à tout ce qui gémit, à tout ce qui roule, à tout ce qui chante, à tout ce qui parle, demandez quelle heure il est. Et le vent, la vague, l'étoile, l'oiseau, l'horloge, vous répondront, il est l'heure de s'enivrer ; pour ne pas être les esclaves martyrisés du temps, enivrez-vous, enivrez-vous sans cesse de vin, de poésie, de vertu, à votre guise.\"\"\"\n",
    "stop_words = set(stopwords.words('french'))\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "print (word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "filtered_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Et', 'si', 'quelquefois', ',', 'marches', \"d'un\", 'palais', ',', \"l'herbe\", 'verte', \"d'un\", 'fossé', ',', 'réveillez', ',', \"l'ivresse\", 'déjà', 'diminuée', 'disparue', ',', 'demandez', 'vent', ',', 'vague', ',', \"l'étoile\", ',', \"l'oiseau\", ',', \"l'horloge\", ';', 'tout', 'fuit', ',', 'tout', 'gémit', ',', 'tout', 'roule', ',', 'tout', 'chante', ',', 'tout', 'parle', ',', 'demandez', 'quelle', 'heure', '.', 'Et', 'vent', ',', 'vague', ',', \"l'étoile\", ',', \"l'oiseau\", ',', \"l'horloge\", ',', 'répondront', ',', \"l'heure\", \"s'enivrer\", ';', 'être', 'esclaves', 'martyrisés', 'temps', ',', 'enivrez-vous', ',', 'enivrez-vous', 'sans', 'cesse', 'vin', ',', 'poésie', ',', 'vertu', ',', 'guise', '.']\n"
     ]
    }
   ],
   "source": [
    "for w in word_tokens:  \n",
    "    if w not in stop_words:  \n",
    "        filtered_sentence.append(w)  \n",
    "        \n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **1. Veille NLT**\n",
    "\n",
    "https://docs.google.com/document/d/1p1eJt4l0cJZjILpwl9RcKvmSCZAUo17h7RSzA_1-Aa4/edit?ts=5fc6087c#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Début de l'exercice\n",
    "\n",
    "### **2) Load, clean and prepare the data**\n",
    "\n",
    "Vectoriser et netoyer vos données. https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "**Data set dowloaded in local sub folder ./data**\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fichier /home/dan/Code/repositoryGIT/simplon-brief7-nltk/SMSSpamCollection.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))  \n",
    "file1 = open(\"/home/dan/Code/repositoryGIT/simplon-brief7-nltk/SMSSpamCollection.txt\")\n",
    "line = file1.read() \n",
    "words = line.split()\n",
    "for r in words:  \n",
    "    if not r in stop_words:  \n",
    "        appendFile = open('SMSSpam_filtered.txt','a')  \n",
    "        appendFile.write(\" \"+r)  \n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import w pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           raw_text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.read_csv(\"SMSSpamCollection.txt\", sep=\"\\t\", names = ['label', 'raw_text'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      label                                           raw_text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      label                                           raw_text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets :\n",
      " count     5572\n",
      "unique       2\n",
      "top        ham\n",
      "freq      4825\n",
      "Name: label, dtype: object \n",
      "\n",
      "Corpus :\n",
      " count                       5572\n",
      "unique                      5169\n",
      "top       Sorry, I'll call later\n",
      "freq                          30\n",
      "Name: raw_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "targets = data_df.label # ham or spam\n",
    "corpus = data_df.raw_text # the docs\n",
    "print(\"Targets :\\n\", targets.describe(), \"\\n\")\n",
    "print(\"Corpus :\\n\", corpus.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "cv = CountVectorizer(stop_words=stopwords)\n",
    "cv_fit = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3531)\t1\n",
      "  (0, 4311)\t1\n",
      "  (0, 5871)\t1\n",
      "  (0, 2312)\t1\n",
      "  (0, 1301)\t1\n",
      "  (0, 1745)\t1\n",
      "  (0, 3615)\t1\n",
      "  (0, 8417)\t1\n",
      "  (0, 4437)\t1\n",
      "  (0, 1743)\t1\n",
      "  (0, 2036)\t1\n",
      "  (0, 3575)\t1\n",
      "  (0, 1074)\t1\n",
      "  (0, 8207)\t1\n",
      "  (1, 5461)\t1\n",
      "  (1, 4473)\t1\n",
      "  (1, 4279)\t1\n",
      "  (1, 8322)\t1\n",
      "  (1, 5488)\t1\n",
      "  (2, 3335)\t1\n",
      "  (2, 2927)\t2\n",
      "  (2, 8376)\t1\n",
      "  (2, 2153)\t1\n",
      "  (2, 8334)\t1\n",
      "  (2, 3064)\t2\n",
      "  :\t:\n",
      "  (5567, 165)\t1\n",
      "  (5567, 5379)\t1\n",
      "  (5568, 3871)\t1\n",
      "  (5568, 3544)\t1\n",
      "  (5568, 3322)\t1\n",
      "  (5568, 2959)\t1\n",
      "  (5569, 5093)\t1\n",
      "  (5569, 5802)\t1\n",
      "  (5569, 7326)\t1\n",
      "  (5570, 3335)\t1\n",
      "  (5570, 8253)\t1\n",
      "  (5570, 4578)\t1\n",
      "  (5570, 5296)\t1\n",
      "  (5570, 8007)\t1\n",
      "  (5570, 7005)\t1\n",
      "  (5570, 2869)\t1\n",
      "  (5570, 3449)\t1\n",
      "  (5570, 1779)\t1\n",
      "  (5570, 3669)\t1\n",
      "  (5570, 4131)\t1\n",
      "  (5570, 912)\t1\n",
      "  (5570, 1540)\t1\n",
      "  (5571, 5205)\t1\n",
      "  (5571, 7828)\t1\n",
      "  (5571, 6460)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cv_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quel est le type Python de vos données après vectorisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8577 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 47370 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quels sont les 10 mots les plus fréquent dans le jeux de données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8577 mots\n"
     ]
    }
   ],
   "source": [
    "print(len(cv.get_feature_names()), \"mots\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(5572, 8577)\n"
     ]
    }
   ],
   "source": [
    "# Transform the sparse matrix into a numpy matrix documents words (mdw)\n",
    "mdw_cv_fit = cv_fit.toarray()\n",
    "\n",
    "# Type of the matrix documents terms mdt\n",
    "print(type(mdw_cv_fit))\n",
    "\n",
    "# Size of the matrix\n",
    "print(mdw_cv_fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 29  1 ...  1  1  1]\n",
      "[4288 4821 4818 ... 3483 7992 1804]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mallika</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malarky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>makiing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maintaining</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>lt</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>gt</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>get</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>ur</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>call</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8577 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  freq\n",
       "0             jot     1\n",
       "1         mallika     1\n",
       "2         malarky     1\n",
       "3         makiing     1\n",
       "4     maintaining     1\n",
       "...           ...   ...\n",
       "8572           lt   316\n",
       "8573           gt   318\n",
       "8574          get   391\n",
       "8575           ur   391\n",
       "8576         call   593\n",
       "\n",
       "[8577 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency of the terms\n",
    "freq_words = np.sum(mdw_cv_fit,axis=0)\n",
    "print(freq_words)\n",
    "# Arg sort\n",
    "index = np.argsort(freq_words)\n",
    "print(index)\n",
    "# Print the matrix words and their frequency\n",
    "mwf = pd.DataFrame({'word':np.asarray(cv.get_feature_names())[index],'freq':freq_words[index]})\n",
    "mwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dix mots les plus fréquents\n",
      "\n",
      "      word  freq\n",
      "8567  good   247\n",
      "8568  know   262\n",
      "8569    go   283\n",
      "8570  free   284\n",
      "8571    ok   293\n",
      "8572    lt   316\n",
      "8573    gt   318\n",
      "8574   get   391\n",
      "8575    ur   391\n",
      "8576  call   593\n"
     ]
    }
   ],
   "source": [
    "print('Les dix mots les plus fréquents\\n')\n",
    "print(mwf[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les moins fréquents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dix mots les moins fréquents\n",
      "\n",
      "           word  freq\n",
      "0           jot     1\n",
      "1       mallika     1\n",
      "2       malarky     1\n",
      "3       makiing     1\n",
      "4   maintaining     1\n",
      "5        mailed     1\n",
      "6       mahfuuz     1\n",
      "7      mahaveer     1\n",
      "8  magicalsongs     1\n",
      "9    manageable     1\n"
     ]
    }
   ],
   "source": [
    "print('Les dix mots les moins fréquents\\n')\n",
    "print(mwf[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracer la distribution de la fréquence des mots présents dans le jeux de données. Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aides/propositions\n",
    "\n",
    "* Stop words avec NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Apprentissage**\n",
    "\n",
    "Que représente la mesure f1 ?\n",
    "\n",
    "*In statistical analysis of binary classification, the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test, where the precision is the number of correctly identified positive results (TP) divided by the number of all positive results (TP + FP), including those not identified correctly, and the recall is the number of correctly identified positive results (TP) divided by the number of all samples that should have been identified as positive (TP + FN).\n",
    "\n",
    "The F1 score is the harmonic mean of the precision and recall. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is F1 = 2 (precision recall) / (precision + recall)*\n",
    "\n",
    "**Quelles sont ces avantages sur d'autre mesure tel que la précision le rappel ou l'accuracy ?**\n",
    "\n",
    "**4) Veille cross validation**  \n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "Utilisez la méthode de ShuffleSplit pour construire vos jeux de données permettant la validation croisée.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits : 10\n",
      "TRAIN: [1978 3989 3935 ... 5226 5390  860] TEST: [3245  944 1044 ... 5556 4205 4293]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [1809 4249  448 ... 5215 3867 2077] TEST: [1086  483  855 ... 3609 3902 1851]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [1688 2618 2319 ...   53 1245 3166] TEST: [ 577 2279 4517 ... 2743 4177 4220]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [  45 2349 4972 ...   98 3693 5304] TEST: [1806 3752 1197 ... 1429 3212 5036]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [4670 3060 3614 ... 2703 5187 2965] TEST: [5528 4971  101 ... 3840 4116 1361]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [3405 4049 1920 ... 3744 4035 4388] TEST: [5162  590 5271 ... 4270 2171  385]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [4541 3491 2231 ... 1486 5147  735] TEST: [ 109 5022 2073 ... 3795 1402 4564]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [ 913 4596 3065 ... 4249   67 4495] TEST: [3572 3423 1340 ... 3964 2446 3145]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [ 323 3821  314 ... 2621 4007 2709] TEST: [2528  859  624 ... 4503 2103 4580]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n",
      "TRAIN: [4218 1896 2868 ... 2892 2458 1741] TEST: [4311 2415 4077 ... 2195 5285 4081]\n",
      "train = 4457 documents => train size ratio : 80%\n",
      "test = 1115 documents => test size ratio : 20%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "X = mdw_cv_fit\n",
    "y = np.array(targets)\n",
    "rs = ShuffleSplit(test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Number of splits :\", rs.get_n_splits(X))\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    rtrain = train_index.shape[0]/ X.shape[0]\n",
    "    rtest = test_index.shape[0] / X.shape[0]\n",
    "    print(\"train =\", len(train_index), \"documents\", \"=> train size ratio :\", \"{:.0%}\".format(rtrain))\n",
    "    print(\"test =\", len(test_index), \"documents\", \"=> test size ratio :\", \"{:.0%}\".format(rtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [4281  585 4545 ... 1435 3902 1247] TEST: [3245  944 1044 ... 5536 1657 3875]\n",
      "train = 2786 documents => train size ratio : 80%\n",
      "test = 1393 documents => test size ratio : 20%\n",
      "TRAIN: [ 130  697 3894 ... 2198 3155 4020] TEST: [1086  483  855 ... 3753 5378 4454]\n",
      "train = 2786 documents => train size ratio : 80%\n",
      "test = 1393 documents => test size ratio : 20%\n",
      "TRAIN: [5333 2732 5328 ... 3759 2612 2957] TEST: [ 577 2279 4517 ... 3669  927 3441]\n",
      "train = 2786 documents => train size ratio : 80%\n",
      "test = 1393 documents => test size ratio : 20%\n",
      "TRAIN: [1862 2587 2267 ... 5023 4154  835] TEST: [1806 3752 1197 ... 3505 3792 4080]\n",
      "train = 2786 documents => train size ratio : 80%\n",
      "test = 1393 documents => test size ratio : 20%\n",
      "TRAIN: [2379 3572  417 ... 1105 2521 1581] TEST: [5528 4971  101 ... 2512  148 2695]\n",
      "train = 2786 documents => train size ratio : 80%\n",
      "test = 1393 documents => test size ratio : 20%\n"
     ]
    }
   ],
   "source": [
    "rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25, random_state=42)\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    rtrain = X_train.shape[0]/ X.shape[0]\n",
    "    rtest = X_test.shape[0] / X.shape[0]\n",
    "    print(\"train =\", len(train_index), \"documents\", \"=> train size ratio :\", \"{:.0%}\".format(rtrain))\n",
    "    print(\"test =\", len(test_index), \"documents\", \"=> test size ratio :\", \"{:.0%}\".format(rtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Train**\n",
    "\n",
    "Fit the models and compare the performance in a table that show\n",
    "\n",
    "* the mean of the f1 score\n",
    "* the standard deviation of the f1 score\n",
    "\n",
    "Qu'observez vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (4457, 8577) \n",
      " y_train shape : (4457,)\n",
      "X_test shape:  (1115, 8577) \n",
      " y_test shape : (1115,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape :\", X_train.shape, \"\\n\", \"y_train shape :\", y_train.shape)\n",
    "#print(type(X_train), type(y_train))\n",
    "print(\"X_test shape: \", X_test.shape, \"\\n\", \"y_test shape :\", y_test.shape)\n",
    "#print(type(X_test), type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[966   0]\n",
      " [ 16 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       1.00      0.89      0.94       149\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.95      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "LR = LogisticRegression()\n",
    "clf = LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[966   0]\n",
      " [ 18 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       1.00      0.88      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "X = mdw_cv_fit\n",
    "y = np.array(targets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression is better than Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96155179, 0.96155179, 0.95915224, 0.95671201, 0.96580076])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro with 5 Cross Validation : 0.9610 (+/- 0.0060)\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_macro with 5 Cross Validation : %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96900147, 0.96043815, 0.96711122, 0.9671907 , 0.96355552])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=cv, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro with shuffle split : 0.9655 (+/- 0.0061)\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_macro with shuffle split : %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation, with or without \"shuffle shift\", doesn't improve the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[965   1]\n",
      " [ 45 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       0.99      0.70      0.82       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.97      0.85      0.90      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "X_TFIDF = vectorizer.fit_transform(corpus)\n",
    "y_TFIDF = np.array(targets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TFIDF, y_TFIDF, test_size=0.2, random_state=42)\n",
    "LR = LogisticRegression()\n",
    "clf = LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression score is worse with TFIDF normalizaztion¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_tf = TfidfVectorizer(stop_words=stopwords)\n",
    "x_tf = v_tf.fit_transform(corpus)\n",
    "\n",
    "idf_values = dict(zip(v_tf.get_feature_names(), v_tf.idf_))\n",
    "words_name = v_tf.get_feature_names()\n",
    "\n",
    "# printing the tfidf vectors\n",
    "print(\"shape :\",x_tf.shape)\n",
    "print(x_tf)\n",
    "# printing the vocabulary\n",
    "print(v_tf.vocabulary_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv2 = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "X2 = cv2.fit_transform(corpus)\n",
    "#print(cv2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(X2.toarray())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"The Array is : \")\n",
    "for i in X2:\n",
    "    print(i, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-415ca462e958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Train pack with tfidf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;31m#corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;31m#target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Train pack with tfidf \n",
    "x = corpus #corpus\n",
    "y = targets #target\n",
    "\n",
    "x_tf_train, x_tf_test, y_train, y_test = train_test_split(x_cv, y, test_size=0.2, random_state=42)                                                   \n",
    "print('-- Training pack TF-IDF:',\"\\n\")\n",
    "print('-- x_tf_train rows :',np.size(x_tf_train))\n",
    "print('-- x_tf_test rows :',np.size(x_tf_test))\n",
    "print('-- ratio in % :', round(np.size(x_tf_test)/(np.size(x_tf_train)+np.size(x_tf_test))*100,2),\"\\n\") \n",
    "\n",
    "#Train pack w/o tfid\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tf, y, test_size=0.20, random_state=0)\n",
    "print('-- Training pack w/o TF-IDF:',\"\\n\")\n",
    "print('-- x_train rows :',np.size(x_train))\n",
    "print('-- x_test rows :',np.size(x_test))\n",
    "print('-- ratio in % :', round(np.size(x_test)/(np.size(x_train)+np.size(x_test))*100,2))\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "X = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print('')\n",
    "print(\"X shape :\", X.shape)\n",
    "print(\"X_train shape :\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearLogistique, svc, random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Logistic regression base set\n",
    "\n",
    "loR = LogisticRegression()\n",
    "loR.fit(x_train, y_train) #Model w/o tf-idf\n",
    "pred = loR.predict(x_test)\n",
    "print(\"-- Loading time : %s secondes. --\" % (time.time() - start_time))\n",
    "print('-- Prediction base_set:',pred[:100],'\\n')\n",
    "print('-- Recall_score base_set:',round(recall_score(y_test, pred, average ='micro'),3))\n",
    "print('-- Precision_score base_set:',round(precision_score(y_test, pred, average ='micro'),3),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression SVM base set\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "predSVM = clf.predict(x_test)\n",
    "print(\"-- Loading time : %s secondes. --\" % (time.time() - start_time))\n",
    "print('-- Prediction base_set:',pred[:100],'\\n')\n",
    "print('-- Recall_score base_set:',round(recall_score(y_test, predSVM, average ='micro'),3))\n",
    "print('-- Precision_score base_set:',round(precision_score(y_test, predSVM, average ='micro'),3),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression base set\n",
    "loR = LogisticRegression()\n",
    "loR.fit(x_train, y_train) #Model w/o tf-idf\n",
    "pred = loR.predict(x_test)\n",
    "print(\"-- Loading time : %s secondes. --\" % (time.time() - start_time))\n",
    "print('-- Prediction base_set:',pred[:100],'\\n')\n",
    "print('-- Recall_score base_set:',round(recall_score(y_test, pred, average ='micro'),3))\n",
    "print('-- Precision_score base_set:',round(precision_score(y_test, pred, average ='micro'),3),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression TF-IDF set\n",
    "loR_tf = LogisticRegression()\n",
    "loR_tf.fit(x_tf_train, y_train) #Model w tf-idf\n",
    "pred_tf = loR_tf.predict(x_tf_test)\n",
    "print(\"-- Loading time : %s secondes. --\" % (time.time() - start_time))\n",
    "print('-- Predition tf-idf set :',pred_tf[:100],'\\n')\n",
    "print('-- Recall_score tf-idf set:',round(recall_score(y_test, pred_tf),3))\n",
    "print('-- Precision_score tf-idf set:',round(precision_score(y_test, pred_tf),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logistic regression SVM base set\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "predSVM = clf.predict(x_test)\n",
    "print(\"-- Loading time : %s secondes. --\" % (time.time() - start_time))\n",
    "print('-- Prediction base_set:',pred[:100],'\\n')\n",
    "print('-- Recall_score base_set:',round(recall_score(y_test, predSVM, average ='micro'),3))\n",
    "print('-- Precision_score base_set:',round(precision_score(y_test, predSVM, average ='micro'),3),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression SVM TF-IDF set\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_tf_train,y_train)\n",
    "predSVM = clf.predict(x_tf_test)\n",
    "print(\"-- Loading time : %s secondes. --\" % (time.time() - start_time))\n",
    "print('-- Prediction TF-IDF_set:',pred[:100],'\\n')\n",
    "print('-- Recall_score TF-IDF_set:',round(recall_score(y_test, predSVM, average ='micro'),3))\n",
    "print('-- Precision_score TF-IDF_set:',round(precision_score(y_test, predSVM, average ='micro'),3),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
